---
title: "Lovable AI"
description: "Unlock powerful models like Gemini and GPT—no API keys, no setup."
icon: "bolt"
---

Normally, adding AI to an app means hunting down API keys, setting up billing with providers, and wiring it all together yourself. Lovable AI makes it simple to quickly add powerful AI features to your app so you can start building smarter and more engaging apps right away.

Some examples include:

- **AI summaries** – automatically condense long text into clear takeaways
- **AI chatbot or agent** – build conversational helpers into your app
- **Sentiment detection** – understand user feedback at scale
- **Document Q&A** – let users ask questions directly against your content
- **Creative generation** – brainstorming, copy drafting, or idea expansion
- **Multilingual translation** – serve global users seamlessly
- **Task completion** – automate repetitive or multi-step workflows (agent functionality)
- **Image and document analysis** -  quickly extract, summarize, and interpret key information from images and documents, turning unstructured content into actionable insights
- **Workflow automation** -  handle repetitive tasks, making decisions, and optimizing processes to save time and reduce errors.

## Enabling Lovable AI

<Note>
  For the best experience, we recommend using Lovable AI with [Lovable Cloud](https://docs.lovable.dev/features/cloud).
</Note>

By default, Lovable AI is enabled for your workspace and in your user preferences. This means Lovable automatically adds AI functionality when requested. You can manage Lovable AI behavior for your projects in your user preferences: **Settings → Connectors → Lovable AI → User preferences**.

### Default AI model

Lovable AI uses **Gemini 2.5 Flash** as the default model. If you want to use a different model or combination of models, you can specify your choice directly in the prompt when requesting AI functionality. For an overview of supported AI models, see [Supported AI models](https://docs.lovable.dev/features/ai#supported-ai-models).

### User preferences

The default setting for AI integration is **Always allow**, meaning Lovable AI will be automatically used in your projects. You can change your preference anytime from **Settings → Connectors → Lovable AI → User preferences**.

Choose between:

- **Always allow**: Lovable automatically performs the action, without asking for review or approval.
- **Ask each time**: Lovable asks for your approval whenever the action is needed. For example, if you want to add a chatbot, you can:
  - **Allow**: enable the integration for the current project.
  - **Deny**: decline the integration for this request (you may be asked again later).
  - **Adjust preferences**: change the default behavior for future projects (does not affect the current project).
- **Never allow**: Lovable blocks the action, informs you that AI is required, and instructs you to enable Lovable AI.

## Usage and pricing

Lovable AI runs on a **usage-based pricing model**. This means your costs scale with how much you use and are not covered by your subscription.

The cost of using Lovable AI is exactly the same as going directly to the LLM provider. There are no hidden fees. To verify costs, refer to the official sources linked in our list of supported AI models below.

Every workspace includes **\$1 of free AI usage per month** to get started. After that, users on paid plans can top up their balance, with costs depending on the underlying model you choose.

<Note>
  **Temporary offering, subject to change:** Until the end of 2025, every workspace gets \$25 Cloud and \$1 AI per month, even for users on the Free plan.
</Note>

You can track and manage your AI usage costs in **Settings → Usage.** For more details and examples, see [Usage-based Cloud and AI pricing](https://docs.lovable.dev/features/cloud#usage-based-cloud-and-ai-pricing).

## Supported AI models

Lovable AI uses **Gemini 2.5 Flash** as its default model, but you can prompt the agent to use a different model or combination of models.

| Model                                                                                                  | Description                                                                                                                                                                               | Best for                                                                                                        |
| ------------------------------------------------------------------------------------------------------ | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------- |
| [**Gemini 3 Pro**](https://deepmind.google/models/gemini/pro/)                                         | Google’s newest flagship Gemini model. Higher reasoning accuracy, larger context window, better multimodal grounding, and more reliable tool-use than 2.5 Pro. Slower and premium-priced. | Advanced agents, complex research, long-horizon reasoning, multimodal analysis requiring high accuracy          |
| [**Nano Banana Pro**](https://deepmind.google/models/gemini-image/pro/)                                | Image-generation and editing model built on Gemini 3 Pro’s image architecture. Studio-quality, high-res visuals, optimized for text in images and multi-image composition.                | Visual asset creation, high-volume image workflows, infographics, rapid prototyping of design/creative content. |
| [**Gemini 2.5 Pro**](https://docs.cloud.google.com/vertex-ai/generative-ai/docs/models/gemini/2-5-pro) | Smartest and most complex Gemini. High reasoning, large context, slower and most expensive.                                                                                               | Deep reasoning, advanced coding, research, complex multimodal tasks                                             |
| [**Gemini 2.5 Flash (default)**](https://deepmind.google/models/gemini/flash/)                         | Balanced model. Faster and cheaper than Pro but still capable of reasoning. Mid-range cost.                                                                                               | Assistants, analysis, general workflows where speed + intelligence balance matters                              |
| [**Gemini 2.5 Flash Lite**](https://deepmind.google/models/gemini/flash-lite/)                         | Fastest and cheapest Gemini. Handles simple tasks at scale, less reasoning depth.                                                                                                         | High-volume, lightweight tasks like classification, summarization, translation                                  |
| [**Gemini 2.5 Flash Image**](https://deepmind.google/models/gemini/image/)                             | Optimized for generating images. Very cheap per image, not meant for text reasoning.                                                                                                      | Image generation, quick visual outputs                                                                          |
| [**GPT-5**](https://openai.com/index/introducing-gpt-5/)                                               | Smartest OpenAI model. Strong reasoning, very accurate, but slowest and most expensive.                                                                                                   | Highest-quality reasoning, accuracy-critical apps, complex decision making                                      |
| [**GPT-5 Mini**](https://platform.openai.com/docs/models/gpt-5-mini)                                   | Balanced GPT-5. Cheaper and faster than GPT-5, less complex but strong general use.                                                                                                       | Assistants, mid-complexity reasoning, business workflows                                                        |
| [**GPT-5 Nano**](https://platform.openai.com/docs/models/gpt-5-nano)                                   | Cheapest and fastest GPT-5. Very basic reasoning, best for quick or simple responses.                                                                                                     | Summaries, classification, extraction, high-volume simple tasks                                                 |

### Best and most cost-effective choices

- **Best overall intelligence**: Gemini 3 Pro, GPT-5 and Gemini 2.5 Pro (deep reasoning, but most expensive)
- **Best balance (speed + cost + smartness)**: GPT-5 Mini and Gemini 2.5 Flash
- **Most cost-effective for scale**: GPT-5 Nano and Gemini 2.5 Flash Lite (simple, fast, cheapest)
- **Best for images**: Nano Banana Pro and Gemini 2.5 Flash Image

## Workspace rate limits

To ensure reliable performance and fair access for all users, Lovable AI applies rate limits per workspace. These limits help maintain system stability, prevent abuse, control costs, and provide a consistent experience for everyone.

If your requests exceed the allowed rate, the server returns a **429 Too Many Requests** status code, and the request will not be processed.

Rate limits are more restrictive for free users, while paid plans include higher thresholds and greater flexibility.

- **Free plan users**: upgrade anytime to increase your limits.
- **Paid plan users**: contact [Lovable Support](https://lovable.dev/support) if you need additional capacity.